# -*- coding: utf-8 -*-
"""ML_Exp6_A33_(RF_pca)ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/169_k9J9p5C-jDMLZzVZwoCl_tzV9-zoW
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import accuracy_score, roc_curve, auc
from sklearn.preprocessing import LabelEncoder

from google.colab import drive
drive.mount('/content/drive')

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/Machine learning Lab/drugbank_clean_no_outliers_IQR.csv')


# Remove zero variance features
non_zero_variance_features = df.loc[:, df.var() > 0]
X = non_zero_variance_features.drop(columns=['targets'])
y = df['targets']

X.info()

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# prompt: perform RF and find training, testing and cv

# Create and train the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train_scaled, y_train)

# Make predictions on the test set
y_pred = rf_model.predict(X_test_scaled)

# Evaluate the model's performance
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Perform cross-validation
cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5)
print("Cross-validation scores:", cv_scores)
print("Mean cross-validation score:", np.mean(cv_scores))

# Training accuracy
y_train_pred = rf_model.predict(X_train_scaled)
training_accuracy = accuracy_score(y_train, y_train_pred)
print("Training Accuracy:", training_accuracy)

# Testing accuracy (already calculated above)
print("Testing Accuracy:", accuracy)

# prompt: perform chi2 on rf and print training, testing and cv of best k

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import accuracy_score, roc_curve, auc
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import chi2

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/Machine learning Lab/drugbank_clean_no_outliers_IQR.csv')


# Remove zero variance features
non_zero_variance_features = df.loc[:, df.var() > 0]
X = non_zero_variance_features.drop(columns=['targets'])
y = df['targets']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Use MinMaxScaler instead of StandardScaler to ensure non-negative values
scaler = MinMaxScaler()  # Changed to MinMaxScaler
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Perform chi2 test
chi2_scores, p_values = chi2(X_train_scaled, y_train)

# Create and train the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train_scaled, y_train)

# Make predictions on the test set
y_pred = rf_model.predict(X_test_scaled)

# Evaluate the model's performance
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Perform cross-validation
cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5)
print("Cross-validation scores:", cv_scores)
print("Mean cross-validation score:", np.mean(cv_scores))

# Training accuracy
y_train_pred = rf_model.predict(X_train_scaled)
training_accuracy = accuracy_score(y_train, y_train_pred)
print("Training Accuracy:", training_accuracy)

# Testing accuracy (already calculated above)
print("Testing Accuracy:", accuracy)

# Print Chi2 results
# You can analyze the chi2_scores and p_values to identify the most relevant features
print("Chi2 Scores:", chi2_scores)
print("P-Values:", p_values)

# prompt: do same for RFE as did for chi2, iterate through all the features to find best num feature find testing, training and cv for all

from sklearn.feature_selection import RFE

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/Machine learning Lab/drugbank_clean_no_outliers_IQR.csv')

# Remove zero variance features
non_zero_variance_features = df.loc[:, df.var() > 0]
X = non_zero_variance_features.drop(columns=['targets'])
y = df['targets']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Iterate through different numbers of features for RFE
for num_features in range(1, X_train.shape[1] + 1):  # Select features in steps of 5

  print(f"\nEvaluating with {num_features} features using RFE:")

  # Create and train the Random Forest model
  rf_model = RandomForestClassifier(n_estimators=100)

  # Perform RFE
  selector = RFE(rf_model, n_features_to_select=num_features, step=1)
  selector = selector.fit(X_train_scaled, y_train)

  # Apply feature selection to training and testing sets
  X_train_rfe = selector.transform(X_train_scaled)
  X_test_rfe = selector.transform(X_test_scaled)

  # Train the model with selected features
  rf_model.fit(X_train_rfe, y_train)

  # Make predictions on the test set
  y_pred = rf_model.predict(X_test_rfe)

  # Evaluate the model's performance
  accuracy = accuracy_score(y_test, y_pred)
  print("Accuracy:", accuracy)

  # Perform cross-validation
  cv_scores = cross_val_score(rf_model, X_train_rfe, y_train, cv=5)
  print("Cross-validation scores:", cv_scores)
  print("Mean cross-validation score:", np.mean(cv_scores))

  # Training accuracy
  y_train_pred = rf_model.predict(X_train_rfe)
  training_accuracy = accuracy_score(y_train, y_train_pred)
  print("Training Accuracy:", training_accuracy)

  # Testing accuracy (already calculated above)
  print("Testing Accuracy:", accuracy)

# Initialize variables
results = {}
best_cv_score = -np.inf  # Setting to negative infinity to ensure any score will be better
best_n_components = None
best_random_state = None

# Loop over a reduced number of components and random_state
for n in [1,2,3,4,5,6,7]:  # Example reduced range for n_components
    for random_state in [0, 500]:  # Reduced random states
        # Apply PCA
        pca = PCA(n_components=n)
        X_train_pca = pca.fit_transform(X_train_scaled)
        X_test_pca = pca.transform(X_test_scaled)

        # Train a Random Forest model
        model_pca = RandomForestClassifier(
            n_estimators=50,  # Reduced number of trees
            max_depth=15,
            min_samples_split=2,
            min_samples_leaf=1,
            random_state=random_state
        )

        # Calculate cross-validation scores
        cv_scores_pca = cross_val_score(model_pca, X_train_pca, y_train, cv=10, n_jobs=-1)  # Parallel processing
        avg_cv_score_pca = np.mean(cv_scores_pca)

        # Store the average CV score and the corresponding n_components and random_state
        results[(n, random_state)] = avg_cv_score_pca

        # Update the best n_components and random_state if this score is higher
        if avg_cv_score_pca > best_cv_score:
            best_cv_score = avg_cv_score_pca
            best_n_components = n
            best_random_state = random_state

# Output the best number of components and random state
print(f"Best number of components: {best_n_components}")
print(f"Best random state: {best_random_state}")
print(f"Best CV accuracy: {best_cv_score:.4f}")

# After finding the best n_components and random_state, retrain the model with those values
pca = PCA(n_components=best_n_components)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Train the Random Forest model with the best parameters
model_pca.fit(X_train_pca, y_train)

# Make predictions and evaluate the model
y_train_pred_pca = model_pca.predict(X_train_pca)
y_test_pred_pca = model_pca.predict(X_test_pca)

# Calculate accuracy scores
train_score_pca = accuracy_score(y_train, y_train_pred_pca)
test_score_pca = accuracy_score(y_test, y_test_pred_pca)

# Output final results
print(f"Train Accuracy with {best_n_components} components and random state {best_random_state}: {train_score_pca:.4f}")
print(f"Test Accuracy with {best_n_components} components and random state {best_random_state}: {test_score_pca:.4f}")

# prompt: use rf hyperparameter for roc curve

import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV

# Define the parameter grid for Random Forest
param_grid = {
    'n_estimators': [500,700],
    'max_depth': [20,40],
    'min_samples_split': [10],
    'min_samples_leaf': [10,20,30]
}

# Create a Random Forest classifier
rf_model = RandomForestClassifier(random_state=best_random_state)

# Use GridSearchCV to find the best hyperparameters
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,
                           scoring='roc_auc', cv=10, n_jobs=-1)

# Fit the GridSearchCV object to the data
grid_search.fit(X_train_pca, y_train)

# Get the best estimator and its parameters
best_rf_model = grid_search.best_estimator_
best_params = grid_search.best_params_

# Train the model with the best hyperparameters
best_rf_model.fit(X_train_pca, y_train)

# Make predictions on the test set
y_test_prob_best_rf = best_rf_model.predict_proba(X_test_pca)[:, 1]

# Calculate the ROC curve and AUC
fpr_best_rf, tpr_best_rf, thresholds_best_rf = roc_curve(y_test, y_test_prob_best_rf)
roc_auc_best_rf = auc(fpr_best_rf, tpr_best_rf)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr_best_rf, tpr_best_rf, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_best_rf)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) with Hyperparameter Tuning')
plt.legend(loc="lower right")
plt.show()

print(f"Best Hyperparameters: {best_params}")
print(f"AUC with Hyperparameter Tuning: {roc_auc_best_rf:.2f}")

