# -*- coding: utf-8 -*-
"""SVM ML lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IcaPishxTyp5CYp3RzcfAVP98imbQrBQ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/Machine learning Lab/drugbank_clean.csv')

data.info()

columns_to_drop = [
    'drugbank-id','type', 'created', 'updated', 'description', 'cas-number', 'unii', 'food-interactions',
    'synthesis-reference', 'indication', 'pharmacodynamics', 'mechanism-of-action',
    'toxicity', 'metabolism', 'absorption', 'half-life', 'protein-binding',
    'route-of-elimination', 'volume-of-distribution', 'clearance', 'ahfs-codes',
    'sequences', 'pathways', 'reactions', 'snp-effects', 'snp-adverse-drug-reactions',
    'carriers', 'transporters', 'fda-label', 'msds', 'atc-codes',	'pdb-entries'
]

# Assuming 'drugbank-id', 'name', 'groups', 'pdb-entries', 'drug-interactions', 'targets', 'average-mass', 'monoisotopic-mass' are kept for your analysis.

# Drop columns from your dataset
data = data.drop(columns=columns_to_drop)

data.info()

data.head(10)

data.describe()

data['targets'] = data['targets'].apply(lambda x: 0 if pd.isnull(x) else 1)

data.head(10)

data.dropna(subset=['name'], inplace=True)

data.dropna(subset=['drug-interactions'], inplace=True)

data.dropna(subset=['state'], inplace=True)

data.dropna(subset=['enzymes'], inplace=True)

data.info()

# prompt: do label encoding

from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Apply label encoding to categorical columns
categorical_cols = ['name','state','groups','drug-interactions','enzymes']  # Replace with actual categorical column names
for col in categorical_cols:
  data[col] = label_encoder.fit_transform(data[col])

# Display the modified DataFrame
data.head()

data.isnull()

data.info()

average_mass_median = data['average-mass'].median()
monoisotopic_mass_median = data['monoisotopic-mass'].median()
print("Average Mass Median:", average_mass_median)
print("Monoisotopic Mass Median:", monoisotopic_mass_median)
# Fill null values with median
data['average-mass'].fillna(average_mass_median, inplace=True)
data['monoisotopic-mass'].fillna(monoisotopic_mass_median, inplace=True)

data.info()

data.isnull()

data.describe()

# prompt: make scartter plot for average-mass and monoisotopic-mas different plot for both

import matplotlib.pyplot as plt
# Scatter plot for 'average-mass'
plt.figure(figsize=(8, 6))
sns.scatterplot(x=data.index, y=data['average-mass'])
plt.title('Scatter Plot of Average Mass')
plt.xlabel('Index')
plt.ylabel('Average Mass')
plt.show()

# Scatter plot for 'monoisotopic-mass'
plt.figure(figsize=(8, 6))
sns.scatterplot(x=data.index, y=data['monoisotopic-mass'])
plt.title('Scatter Plot of Monoisotopic Mass')
plt.xlabel('Index')
plt.ylabel('Monoisotopic Mass')
plt.show()

# prompt: plot box plot to track outliers for all columns

import matplotlib.pyplot as plt
# Box plots for numerical columns to detect outliers
numerical_cols = ['average-mass', 'monoisotopic-mass']
for col in numerical_cols:
  plt.figure()
  sns.boxplot(x=data[col])
  plt.title(f'Box Plot of {col}')
  plt.show()

# prompt: use z-score to eliminate outliers\

import numpy as np
from scipy import stats

# Calculate z-scores for numerical columns
numerical_cols = ['average-mass', 'monoisotopic-mass']
z_scores = stats.zscore(data[numerical_cols])

# Set a threshold for outlier detection (e.g., 3 standard deviations)
threshold = 3

# Filter data to remove outliers
data_filtered = data[(np.abs(z_scores) < threshold).all(axis=1)]

# Display the shape of the filtered DataFrame
print("Shape of filtered data:", data_filtered.shape)

# prompt: plot box plot to track outliers for all columns

import matplotlib.pyplot as plt
# Box plots for numerical columns to detect outliers
numerical_cols = ['average-mass', 'monoisotopic-mass']
for col in numerical_cols:
  plt.figure()
  sns.boxplot(x=data_filtered[col])
  plt.title(f'Box Plot of {col}')
  plt.show()

data.describe()

# prompt: export cleaned data as csv file

# Assuming 'data_filtered_ior' is your final cleaned DataFrame
data_filtered.to_csv('cleaned_drug_data(z_score).csv', index=False)

# prompt: perform svm on cleaned data and give me training, testing and cv

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score

# Assuming 'targets' is your target variable and the rest are features
X = data_filtered.drop('targets', axis=1)
y = data_filtered['targets']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Initialize SVM classifier
svm_classifier = SVC()  # You can try different kernels like 'rbf', 'poly'

# Train the classifier
svm_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svm_classifier.predict(X_test)
y_train_pred = svm_classifier.predict(X_train)


# Evaluate the model
print("Training Accuracy:", accuracy_score(y_train, y_train_pred))
print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Perform cross-validation
cv_scores = cross_val_score(svm_classifier, X, y, cv=20)  # 5-fold cross-validation
print("\nCross-Validation Scores:", cv_scores)
print("Average CV Score:", cv_scores.mean())

import matplotlib.pyplot as plt
# Assuming 'cv_scores' contains your cross-validation scores
plt.figure(figsize=(8, 6))
plt.plot(range(1, len(cv_scores) + 1), cv_scores, marker='o', linestyle='--')
plt.title('Cross-Validation Scores')
plt.xlabel('Fold')
plt.ylabel('Score')
plt.grid(True)
plt.show()

# prompt: create a loop to get the best random state performance in svm

best_accuracy = 0
best_random_state = None

for random_state in range(0, 5000):
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)
  svm_classifier = SVC()
  svm_classifier.fit(X_train, y_train)
  y_pred = svm_classifier.predict(X_test)
  accuracy = accuracy_score(y_test, y_pred)

  if accuracy > best_accuracy:
    best_accuracy = accuracy
    best_random_state = random_state

print("Best Random State:", best_random_state)
print("Best Accuracy:", best_accuracy)

X_train_br, X_test_br, y_train_br, y_test_br = train_test_split(X, y, test_size=0.2, random_state=best_random_state)

# Initialize SVM classifier
svm_classifier_rs = SVC(random_state= best_random_state)  # You can try different kernels like 'rbf', 'poly'

# Train the classifier
svm_classifier_rs.fit(X_train_br, y_train_br)

# Make predictions on the test set
y_pred = svm_classifier_rs.predict(X_test_br)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test_br, y_pred))
print("\nClassification Report:\n", classification_report(y_test_br, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test_br, y_pred))

# Perform cross-validation
cv_scores = cross_val_score(svm_classifier_rs, X, y, cv=20)  # 5-fold cross-validation
print("\nCross-Validation Scores:", cv_scores)
print("Average CV Score:", cv_scores.mean())

plt.figure(figsize=(8, 6))
plt.plot(range(1, len(cv_scores) + 1), cv_scores, marker='o', linestyle='--')
plt.title('Cross-Validation Scores')
plt.xlabel('Fold')
plt.ylabel('Score')
plt.grid(True)
plt.show()

# prompt: run the for loop for k for 50 times and select K with most repetetion

from sklearn.feature_selection import chi2, SelectKBest

k_counts = {}
for _ in range(1):
  best_accuracy = 0
  best_k = 0

  for k in range(1, 8):
    # Feature selection
    selector = SelectKBest(score_func=chi2, k=k)
    X_new = selector.fit_transform(X, y)

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2)

    # Initialize SVM classifier
    svm_classifier = SVC()

    # Train the classifier
    svm_classifier.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = svm_classifier.predict(X_test)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)

    if accuracy > best_accuracy:
      best_accuracy = accuracy
      best_k = k

  # Update k counts
  if best_k in k_counts:
    k_counts[best_k] += 1
  else:
    k_counts[best_k] = 1

# Find the most frequent k
most_frequent_k = max(k_counts, key=k_counts.get)

print(f"Most frequently selected k: {most_frequent_k}")

# select above Fetures in X and perform svm

k = most_frequent_k

selector = SelectKBest(score_func=chi2, k=k)
X_selected = selector.fit_transform(X, y)

  # Get the indices of the selected features
selected_feature_indices = selector.get_support(indices=True)

  # Get the names of the selected features
selected_feature_names = X.columns[selected_feature_indices]

print(f"Selected Features for k={k}: {selected_feature_names}")

# Split the data into training and testing sets
X_train_selected, X_test_selected, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)

# Initialize SVM classifier
svm_classifier_selected = SVC()

# Train the classifier
svm_classifier_selected.fit(X_train_selected, y_train)

# Make predictions on the test set
y_pred_selected = svm_classifier_selected.predict(X_test_selected)
y_train_pred_selected = svm_classifier_selected.predict(X_train_selected)
# Evaluate the model
print("Training Accuracy (Selected Features):", accuracy_score(y_train, y_train_pred_selected))
print("Testing Accuracy (Selected Features):", accuracy_score(y_test, y_pred_selected))
print("\nClassification Report (Selected Features):\n", classification_report(y_test, y_pred_selected))
print("\nConfusion Matrix (Selected Features):\n", confusion_matrix(y_test, y_pred_selected))

new_cv_scores = cross_val_score(svm_classifier_selected, X_train_selected, y_train, cv=20)  # 5-fold cross-validation
print("\nCross-Validation Scores:", new_cv_scores)
print("Average CV Score:", new_cv_scores.mean())

import matplotlib.pyplot as plt
# Assuming 'cv_scores' contains your cross-validation scores
plt.figure(figsize=(8, 6))
plt.plot(range(1, len(new_cv_scores) + 1), new_cv_scores, marker='o', linestyle='--')
plt.title('Cross-Validation Scores')
plt.xlabel('Fold')
plt.ylabel('Score')
plt.grid(True)
plt.show()

# prompt: do same for RFE as did for chi 2 k

import matplotlib.pyplot as plt
import numpy as np
from sklearn.feature_selection import RFE

# Initialize lists to store results
num_features = []
accuracies = []

for k in range(1, 8):
  # Initialize SVM classifier
  estimator = SVC(kernel="linear")

  # Initialize RFE with the estimator and desired number of features
  selector = RFE(estimator, n_features_to_select=k)

  # Fit RFE to the data
  selector = selector.fit(X, y)

  # Get the selected features
  X_selected = X.iloc[:, selector.support_]

  # Split the data into training and testing sets
  X_train_selected, X_test_selected, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)

  # Initialize SVM classifier
  svm_classifier_selected = SVC()

  # Train the classifier
  svm_classifier_selected.fit(X_train_selected, y_train)

  # Make predictions on the test set
  y_pred_selected = svm_classifier_selected.predict(X_test_selected)

  # Evaluate the model
  accuracy = accuracy_score(y_test, y_pred_selected)

  # Store results
  num_features.append(k)
  accuracies.append(accuracy)

  print(f"Accuracy with {k} features (RFE): {accuracy}")

# Find the best number of features
best_k = num_features[np.argmax(accuracies)]
best_accuracy = np.max(accuracies)

print(f"\nBest accuracy: {best_accuracy} achieved with {best_k} features (RFE)")

selected_feature_indices = selector.get_support(indices=True)

# Get the names of the selected features
selected_feature_names = X.columns[selected_feature_indices]

print("Selected Features for Best RFE:", selected_feature_names)

# Plot the results
plt.figure(figsize=(8, 6))
plt.plot(num_features, accuracies, marker='o', linestyle='--')
plt.title('Accuracy vs. Number of Features (RFE)')
plt.xlabel('Number of Features')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()

# prompt: Selected Features (RFE): Index(['state', 'groups', 'enzymes', 'average-mass', 'monoisotopic-mass'], dtype='object')
# select these features and perfoem svm

# Select the features
X_selected_rfe = ['state', 'groups', 'drug-interactions', 'enzymes',
       'average-mass', 'monoisotopic-mass']

# Split the data into training and testing sets
X_train_selected_rfe, X_test_selected_rfe, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)

# Initialize SVM classifier
svm_classifier_selected_rfe = SVC()

# Train the classifier
svm_classifier_selected_rfe.fit(X_train_selected_rfe, y_train)

# Make predictions on the test set
y_pred_selected_rfe = svm_classifier_selected_rfe.predict(X_test_selected_rfe)
y_train_pred_selected_rfe = svm_classifier_selected_rfe.predict(X_train_selected_rfe)
# Evaluate the model
print("Training Accuracy (Selected Features RFE):", accuracy_score(y_train, y_train_pred_selected_rfe))
print("Testing Accuracy (Selected Features RFE):", accuracy_score(y_test, y_pred_selected_rfe))
print("\nClassification Report (Selected Features RFE):\n", classification_report(y_test, y_pred_selected_rfe))
print("\nConfusion Matrix (Selected Features RFE):\n", confusion_matrix(y_test, y_pred_selected_rfe))

new_cv_scores = cross_val_score(svm_classifier_selected_rfe, X_train_selected_rfe, y_train, cv=20)  # 5-fold cross-validation
print("\nCross-Validation Scores:", new_cv_scores)
print("Average CV Score:", new_cv_scores.mean())

new_cv_scores = cross_val_score(svm_classifier_selected, X_selected, y, cv=20)  # 5-fold cross-validation
print("\nCross-Validation Scores:", new_cv_scores)
print("Average CV Score:", new_cv_scores.mean())

import matplotlib.pyplot as plt
# Assuming 'cv_scores' contains your cross-validation scores
plt.figure(figsize=(8, 6))
plt.plot(range(1, len(new_cv_scores) + 1), new_cv_scores, marker='o', linestyle='--')
plt.title('Cross-Validation Scores')
plt.xlabel('Fold')
plt.ylabel('Score')
plt.grid(True)
plt.show()

# 6. Hyperparameter Tuning using Grid Search
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [0.01, 0.1, 1, 10],
    'kernel': ['linear', 'rbf']
}

# Perform Grid Search on the full dataset with the best features from Chi-Squared
grid_search_chi2 = GridSearchCV(SVC(), param_grid, scoring='accuracy', cv=10, n_jobs=50)
grid_search_chi2.fit(X_train_selected, y_train)

print("Best parameters from Grid Search (Chi-Squared):", grid_search_chi2.best_params_)
print("Best cross-validated score from Grid Search (Chi-Squared):", grid_search_chi2.best_score_)

# Testing the best model from Grid Search
best_model_chi2 = grid_search_chi2.best_estimator_
y_pred_best_model_chi2 = best_model_chi2.predict(X_test)

print("Final Testing accuracy of best model (Chi-Squared):", accuracy_score(y_test, y_pred_best_model_chi2))
print("Classification report (best model, Chi-Squared):")
print(classification_report(y_test, y_pred_best_model_chi2))

# prompt:  perform hyper parameter tuning and find training and testing accuracy and cv and generate a classification report

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'C': [0.1, 1, 10],  # Regularization parameter
    'gamma': [1, 0.1, 0.01, 0.001],  # Kernel coefficient
    'kernel': ['linear', 'rbf']  # Kernel type
}

# Create an SVC model
model = SVC()

# Create GridSearchCV object
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=10)

# Fit the grid search to the data
grid_search.fit(X_train, y_train)

# Print the best parameters
print("Best Parameters:", grid_search.best_params_)

# Get the best model
best_model = grid_search.best_estimator_

# Make predictions on the training and testing sets
y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)

# Calculate training and testing accuracy
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

# Perform cross-validation
cv_scores = cross_val_score(best_model, X_selected, y, cv=5)
cv_score = cv_scores.mean()

print(f"Training Accuracy: {train_accuracy:.4f}")
print(f"Testing Accuracy: {test_accuracy:.4f}")
print(f"Cross-Validation Score: {cv_score:.4f}")

# Generate a classification report
print(classification_report(y_test, y_test_pred))

# prompt: param grid for svc in this case

param_grid = {
    'C': [0.1, 1, 10, 100],  # Regularization parameter
    'gamma': [0.001, 0.01, 0.1, 1],  # Kernel coefficient
    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # Kernel type
}